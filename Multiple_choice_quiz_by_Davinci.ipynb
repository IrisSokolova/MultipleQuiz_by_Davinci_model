{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef3fb00",
   "metadata": {},
   "source": [
    "### Multiple choice quiz generated by OpenAI\n",
    "\n",
    "Each question can have up to end possible answers, so we should be able to tell it.\n",
    "\n",
    "    * I want four questions with each question, having four possible answers.\n",
    "\n",
    "    * Must tell the model exactly how to specify the correct answer.\n",
    "\n",
    "    * Crucial to separate out the questions from the answers in order to have the quiz and also make a solution key that we can actually have a quiz without the answer embedded somewhere in the question.\n",
    "\n",
    "To do list:\n",
    "\n",
    "    1. Create a quiz.\n",
    "\n",
    "    2. Separate out the question from the answers\n",
    "\n",
    "    3. Simulate an exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58a44f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2430752",
   "metadata": {},
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f07a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of fantasy of Davinci model\n",
    "prompt = 'Give me detail about the technology startup callad Mimi and Pimo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c25b3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(engine= 'text-davinci-003',\n",
    "                                    prompt = prompt,\n",
    "                                    max_tokens = 256,\n",
    "                                    temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781baece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mimi and Pimo is a technology startup founded by a team of experienced entrepreneurs and engineers. The startup is focused on building advanced AI-powered products to help people to better understand their health and lifestyle. Its products are designed to help people to manage their health, understand their lifestyle, and improve their overall well-being.\n",
      "\n",
      "Mimi and Pimoâ€™s products are based on advanced machine learning and AI technologies, including natural language processing, computer vision, and deep learning. The company uses this technology to create personalized health and lifestyle profiles for each user, and then provides personalized, actionable insights and advice to help them stay healthy and achieve their goals.\n",
      "\n",
      "Mimi and Pimo also offer a range of products for businesses and healthcare providers, including AI-powered health management tools and analytics solutions. The company is working to develop products that can help healthcare providers reduce costs, improve patient outcomes, and increase efficiencies.\n"
     ]
    }
   ],
   "source": [
    "# Model hallucinate information\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ec154f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model, if it does not know the answer, say: 'I do not know'\n",
    "prompt = 'Give me detail about the technology startup  callad Mimi and Pimo. Only answer if you are 100% sure that this company exist, othewise answer \"I do not know\" '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f955842",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(engine= 'text-davinci-003',\n",
    "                                    prompt = prompt,\n",
    "                                    max_tokens = 256,\n",
    "                                    temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f071dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I do not know.\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b135014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't ask questions that could\n",
    "\n",
    "# be answered by opinion, use only actual 100% correct fact.\n",
    "\n",
    "# They must only be answered by a single correct answer and they must be based.\n",
    "\n",
    "# In fact, you could also ask the model to actually give it your sourcing.\n",
    "\n",
    "# So try to add sources to text files or Wikipedia links that would support your answer.\n",
    "\n",
    "def create_test_prompt(topic, num_questions, num_possible_answers):\n",
    "    prompt = f'create multiple couce quize on the topics of {topic} consisting of {num_questions} '\\\n",
    "        +f'Each question shoupd have {num_possible_answers} options. '\\\n",
    "        +f'Also include the correct answer for each question the starting string \"Correct Answer\": '\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb01cba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'create multiple couce quize on the topics of Python consisting of 4 Each question shoupd have 4 options. Also onclude the correct answer for each question the starting string \"Correct Answer\": '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_test_prompt('Python', 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12dd13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(engine= 'text-davinci-003',\n",
    "                                    prompt = create_test_prompt('US History', 4,4),\n",
    "                                    max_tokens = 256,\n",
    "                                    temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0726be4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question 1: In what year did the United States become an independent nation?\n",
      "A. 1776\n",
      "B. 1607\n",
      "C. 1789\n",
      "D. 1812\n",
      "Correct Answer: A. 1776\n",
      "\n",
      "Question 2: Who was the first president of the United States?\n",
      "A. George Washington\n",
      "B. Thomas Jefferson\n",
      "C. John Adams\n",
      "D. John Quincy Adams\n",
      "Correct Answer: A. George Washington\n",
      "\n",
      "Question 3: What is the name of the document that declared the independence of the United States?\n",
      "A. The Magna Carta\n",
      "B. The Bill of Rights\n",
      "C. The Constitution\n",
      "D. The Declaration of Independence \n",
      "Correct Answer: D. The Declaration of Independence\n",
      "\n",
      "Question 4: What event was the primary catalyst for the American Revolution?\n",
      "A. The Boston Massacre\n",
      "B. The Stamp Act\n",
      "C. The French and Indian War\n",
      "D. The Battle of Bunker Hill\n",
      "Correct Answer: B. The Stamp Act\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two dictionaries that I can easily loop through, which means I should be able to\n",
    "\n",
    "# simulate an exam and perform automatic reading, which we're going to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "414597eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_student_view(test, num_questions):\n",
    "    student_view = {1:''}\n",
    "    question_number = 1\n",
    "    for line in test.split('\\n'):\n",
    "        if not line.startswith('Correct Answer:'):\n",
    "            student_view[question_number] += line+ '\\n'\n",
    "        else:\n",
    "            if question_number < num_questions:\n",
    "                question_number +=1\n",
    "                student_view[question_number] = ''\n",
    "    return student_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fed7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_student_view(response['choices'][0]['text'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe798bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question 1: In what year did the United States become an independent nation?\n",
      "A. 1776\n",
      "B. 1607\n",
      "C. 1789\n",
      "D. 1812\n",
      "\n",
      "\n",
      "Question 2: Who was the first president of the United States?\n",
      "A. George Washington\n",
      "B. Thomas Jefferson\n",
      "C. John Adams\n",
      "D. John Quincy Adams\n",
      "\n",
      "\n",
      "Question 3: What is the name of the document that declared the independence of the United States?\n",
      "A. The Magna Carta\n",
      "B. The Bill of Rights\n",
      "C. The Constitution\n",
      "D. The Declaration of Independence \n",
      "\n",
      "\n",
      "Question 4: What event was the primary catalyst for the American Revolution?\n",
      "A. The Boston Massacre\n",
      "B. The Stamp Act\n",
      "C. The French and Indian War\n",
      "D. The Battle of Bunker Hill\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in result:\n",
    "    print(result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0da507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answers(test, num_questions):\n",
    "    answers = {1:''}\n",
    "    question_number = 1\n",
    "    for line in test.split('\\n'):\n",
    "        if line.startswith('Correct Answer:'):\n",
    "            answers[question_number] += line+ '\\n'\n",
    "            \n",
    "            if question_number < num_questions:\n",
    "                question_number +=1\n",
    "                answers[question_number] = ''\n",
    "       \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33833a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Correct Answer: A. 1776\\n',\n",
       " 2: 'Correct Answer: A. George Washington\\n',\n",
       " 3: 'Correct Answer: D. The Declaration of Independence\\n',\n",
       " 4: 'Correct Answer: B. The Stamp Act\\n'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_answers(response['choices'][0]['text'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "571388af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate an exam and perform automatic reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "896d31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_view = create_student_view(response['choices'][0]['text'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d068fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = extract_answers(response['choices'][0]['text'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db63ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the Exam\n",
    "def take(student_view):\n",
    "    student_answers = {}\n",
    "    for question, question_view in student_view.items():\n",
    "        print(question_view)\n",
    "        answer = input('Enter you answer: ')\n",
    "        student_answers[question] = answer\n",
    "    return student_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7697dcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, '\\n\\nQuestion 1: In what year did the United States become an independent nation?\\nA. 1776\\nB. 1607\\nC. 1789\\nD. 1812\\n'), (2, '\\nQuestion 2: Who was the first president of the United States?\\nA. George Washington\\nB. Thomas Jefferson\\nC. John Adams\\nD. John Quincy Adams\\n'), (3, '\\nQuestion 3: What is the name of the document that declared the independence of the United States?\\nA. The Magna Carta\\nB. The Bill of Rights\\nC. The Constitution\\nD. The Declaration of Independence \\n'), (4, '\\nQuestion 4: What event was the primary catalyst for the American Revolution?\\nA. The Boston Massacre\\nB. The Stamp Act\\nC. The French and Indian War\\nD. The Battle of Bunker Hill\\n')])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_view.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea949c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question 1: In what year did the United States become an independent nation?\n",
      "A. 1776\n",
      "B. 1607\n",
      "C. 1789\n",
      "D. 1812\n",
      "\n",
      "Enter you answer: a\n",
      "\n",
      "Question 2: Who was the first president of the United States?\n",
      "A. George Washington\n",
      "B. Thomas Jefferson\n",
      "C. John Adams\n",
      "D. John Quincy Adams\n",
      "\n",
      "Enter you answer: a\n",
      "\n",
      "Question 3: What is the name of the document that declared the independence of the United States?\n",
      "A. The Magna Carta\n",
      "B. The Bill of Rights\n",
      "C. The Constitution\n",
      "D. The Declaration of Independence \n",
      "\n",
      "Enter you answer: c\n",
      "\n",
      "Question 4: What event was the primary catalyst for the American Revolution?\n",
      "A. The Boston Massacre\n",
      "B. The Stamp Act\n",
      "C. The French and Indian War\n",
      "D. The Battle of Bunker Hill\n",
      "\n",
      "Enter you answer: d\n"
     ]
    }
   ],
   "source": [
    "student_answers = take(student_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43e78457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a', 2: 'a', 3: 'c', 4: 'd'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "294eb91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare two dictionary\n",
    "answers[2][16] #'Correct Answer: A. George Washington\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8b9c4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade(correct_answer_dict, student_answers):\n",
    "    correct_answers = 0\n",
    "    for question, answer in student_answers.items():\n",
    "        if answer.upper() == correct_answer_dict[question][16]:\n",
    "            correct_answers +=1\n",
    "    grade = 100*correct_answers / len(answers)\n",
    "    \n",
    "    if grade < 60:\n",
    "        passed = 'No pass'\n",
    "    else:\n",
    "        passed = 'Pass!'\n",
    "    return f'{correct_answers}/{len(answers)} correct! You got {grade} grade, {passed}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d99c1c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2/4 correct! You got 50.0 grade, No pass'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade(answers, student_answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
